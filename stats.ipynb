{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "import pypdfium2 as pdfium\n",
    "from PIL import Image, ImageEnhance\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertPdfToImage(path):\n",
    "    pdf = pdfium.PdfDocument(path)\n",
    "    n_pages = len(pdf)\n",
    "    images = []\n",
    "    for page_number in range(n_pages):\n",
    "        page = pdf.get_page(page_number)\n",
    "        pil_image = page.render(\n",
    "            scale=1,\n",
    "            rotation=0,\n",
    "            crop=(0, 0, 0, 0),\n",
    "            grayscale=True\n",
    "        )\n",
    "        image = pil_image.to_pil()\n",
    "        images.append(image)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMON LIBRARIES\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# DATA SET PREPARATION AND LOADING\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "# VISUALIZATION\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "# CONFIGURATION\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "# EVALUATION\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "# TRAINING\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "ARCHITECTURE = \"mask_rcnn_R_101_FPN_3x\"\n",
    "CONFIG_FILE_PATH = f\"COCO-InstanceSegmentation/{ARCHITECTURE}.yaml\"\n",
    "MAX_ITER = 3000\n",
    "EVAL_PERIOD = 200\n",
    "BASE_LR = 0.001\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "train_images_path = \"C:/Users/Arpit/Downloads/Signature Extractor.v1i.coco/train\"\n",
    "test_images_path = \"C:/Users/Arpit/Downloads/Signature Extractor.v1i.coco/test\"\n",
    "val_images_path = \"C:/Users/Arpit/Downloads/Signature Extractor.v1i.coco/valid\"\n",
    "\n",
    "train_annotation_path = \"C:/Users/Arpit/Downloads/Signature Extractor.v1i.coco/annotations/train_annotations.coco.json\"\n",
    "test_annotation_path = \"C:/Users/Arpit/Downloads/Signature Extractor.v1i.coco/annotations/test_annotations.coco.json\"\n",
    "val_annotation_path = \"C:/Users/Arpit/Downloads/Signature Extractor.v1i.coco/annotations/valid_annotations.coco.json\"\n",
    "\n",
    "train_dataset_name = \"train_dataset\"\n",
    "test_dataset_name = \"test_dataset\"\n",
    "val_dataset_name = \"valid_dataset\"\n",
    "\n",
    "# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(train_dataset_name, {}, train_annotation_path, train_images_path)\n",
    "register_coco_instances(test_dataset_name, {}, test_annotation_path, test_images_path)\n",
    "register_coco_instances(val_dataset_name, {}, val_annotation_path, val_images_path)\n",
    "\n",
    "metadata = MetadataCatalog.get(train_dataset_name)\n",
    "dataset_train = DatasetCatalog.get(train_dataset_name)\n",
    "\n",
    "class Detector:\n",
    "    def __init__(self):\n",
    "        self.cfg = get_cfg()\n",
    "        self.cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
    "        self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n",
    "        self.cfg.DATASETS.TRAIN = (train_dataset_name,)\n",
    "        self.cfg.DATASETS.TEST = (test_dataset_name,)\n",
    "        self.cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "        self.cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
    "        self.cfg.DATALOADER.NUM_WORKERS = 2\n",
    "        self.cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "        self.cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "        self.cfg.SOLVER.BASE_LR = BASE_LR\n",
    "        self.cfg.SOLVER.MAX_ITER = MAX_ITER\n",
    "        self.cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
    "        self.cfg.MODEL.DEVICE = 'cpu'\n",
    "        #Load model config and pretrained model\n",
    "        self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "        self.cfg.MODEL.DEVICE = 'cpu'\n",
    "        self.cfg.MODEL.WEIGHTS = os.path.join(\"model_final.pth\")\n",
    "        self.predictor = DefaultPredictor(self.cfg)\n",
    "\n",
    "    def onImage_path(self, image_path):\n",
    "        image = cv2.imread(image_path)\n",
    "        predictions = self.predictor(image)\n",
    "        viz = Visualizer(image[:,:,::-1], metadata = metadata, instance_mode = ColorMode.IMAGE_BW)\n",
    "        output = viz.draw_instance_predictions(predictions[\"instances\"].to(\"cpu\"))\n",
    "        return output\n",
    "        \n",
    "    def onImage(self, image):\n",
    "        if(image is None): \n",
    "            return None\n",
    "        predictions = self.predictor(image)\n",
    "        # viz = Visualizer(image[:,:,::-1], metadata = metadata, instance_mode = ColorMode.IMAGE_BW)\n",
    "        # output = viz.draw_instance_predictions(predictions[\"instances\"].to(\"cpu\"))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertPdfToImage(pdf_bytes):\n",
    "    pdf = pdfium.PdfDocument(pdf_bytes)\n",
    "    n_pages = len(pdf)\n",
    "    for page_number in range(n_pages):\n",
    "        page = pdf.get_page(page_number)\n",
    "        pil_image = page.render(\n",
    "            scale=1,\n",
    "            rotation=0,\n",
    "            crop=(0, 0, 0, 0),\n",
    "            grayscale=False\n",
    "        )\n",
    "    image = pil_image.to_pil()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr = PaddleOCR(det_model_dir='C:/Users/Arpit/Downloads/en_PP-OCRv3_det_distill_train', rec_model_dir='C:/Users/Arpit/Downloads/en_PP-OCRv3_rec_train', use_gpu=False)\n",
    "detector = Detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_text(image, target_text):\n",
    "    result = ocr.ocr(image, cls=False)\n",
    "    target_text_found = False\n",
    "    bbox_coords = None\n",
    "    for line in result:\n",
    "        for word_info in line:\n",
    "            box = word_info[0]\n",
    "            text = word_info[1][0]\n",
    "            text = str(text)\n",
    "            if target_text in text:\n",
    "                bbox_coords = np.array(box, dtype=np.int32)\n",
    "                target_text_found = True\n",
    "                break\n",
    "            if target_text_found:\n",
    "                break\n",
    "\n",
    "            if bbox_coords is not None:\n",
    "                # Crop the bounding box area from the image\n",
    "                xmin = int(min(p[0] for p in bbox_coords)) + 83\n",
    "                xmax = int(max(p[0] for p in bbox_coords)) + 0\n",
    "                ymin = int(min(p[1] for p in bbox_coords)) - 20\n",
    "                ymax = int(max(p[1] for p in bbox_coords)) - 20\n",
    "\n",
    "                xmax += 70\n",
    "                ymax += 40\n",
    "    return bbox_coords\n",
    "\n",
    "def get_pensioner_sign_area(image):\n",
    "    affixed_bbox = get_target_text(image, \"affixed\")\n",
    "    \n",
    "    xmin = affixed_bbox[2][0]\n",
    "    xmax = image.shape[1]\n",
    "    ymin = 0\n",
    "    ymax = affixed_bbox[2][1] + 50\n",
    "    \n",
    "    roi = [xmin, xmax, ymin, ymax]\n",
    "    cropped = image[ymin:ymax, xmin:xmax]\n",
    "    return cropped, roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_path = \"C:/Users/Arpit/Downloads/SCANNED LIFE CERTIFICATES/SCANNED LIFE CERTIFICATES/Paralell\"\n",
    "pdfs_in_parallel = os.listdir(parallel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# Define the path to save the CSV file\n",
    "csv_file_path = 'final_stats.csv'\n",
    "\n",
    "# Initialize the CSV file with headers if it doesn't exist\n",
    "if not os.path.exists(csv_file_path):\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['PDF File', 'Status', 'ROI', 'Signature_box' 'Error Message'])\n",
    "        \n",
    "# Load the list of already processed files\n",
    "processed_files = set()\n",
    "if os.path.exists(csv_file_path):\n",
    "    with open(csv_file_path, mode='r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip header\n",
    "        for row in reader:\n",
    "            processed_files.add(row[0])\n",
    "\n",
    "# Process PDFs in parallel\n",
    "for pdf in pdfs_in_parallel:\n",
    "   \n",
    "    if pdf in processed_files:\n",
    "        # Skip this file as it has already been processed\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(parallel_path, pdf)\n",
    "    try:\n",
    "        image = convertPdfToImage(path)\n",
    "        image = np.array(image)\n",
    "\n",
    "        if image is None:\n",
    "            # Log error and save to CSV (error in converting PDF to image)\n",
    "            print(\"image None\")\n",
    "            with open(csv_file_path, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([pdf, 'Failed', 'NA', 'NA', 'Error in converting PDF to image'])\n",
    "            continue\n",
    "        \n",
    "        cropped, roi = get_pensioner_sign_area(image)\n",
    "        print(cropped.shape)\n",
    "        if roi is None or roi == []:\n",
    "            # Log error and save to CSV (ROI not found, OCR error)\n",
    "            print(\"roi none\")\n",
    "            with open(csv_file_path, mode='a', newline='') as file:\n",
    "                \n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([pdf, 'Failed', 'NA', 'NA', 'ROI not found or OCR error'])\n",
    "            continue\n",
    "        \n",
    "        if cropped is None:\n",
    "            print(\"cropped none\")\n",
    "            \n",
    "            # Log error and save to CSV (error in cropping the signature area)\n",
    "            with open(csv_file_path, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([pdf, 'Failed', 'NA', 'NA', 'Error in cropping the signature area'])\n",
    "            continue\n",
    "        \n",
    "        outputs = detector.onImage(cropped)\n",
    "        # viz = Visualizer(image[:,:,::-1], metadata = metadata, instance_mode = ColorMode.IMAGE_BW)\n",
    "        # output = viz.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        print(outputs)\n",
    "        \n",
    "         # Check if outputs contain predictions\n",
    "        if outputs is None or outputs['instances'].pred_boxes.tensor.size(0) == 0:\n",
    "            print(\"pred none\")\n",
    "            with open(csv_file_path, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([pdf, 'Failed', f'{roi}', 'NA', 'Signature not detected'])\n",
    "            continue\n",
    "        \n",
    "        pred_boxes = outputs['instances'].pred_boxes.tensor.tolist()\n",
    "        pred_classes = outputs['instances'].pred_classes.numpy()\n",
    "        print(pred_boxes)\n",
    "            \n",
    "        # If everything is successful, log success\n",
    "        with open(csv_file_path, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([pdf, 'Success', f'{roi}', f'{pred_boxes}', 'Processed successfully'])\n",
    "    \n",
    "    except Exception as e:\n",
    "        \n",
    "        # Log unexpected errors to CSV\n",
    "        with open(csv_file_path, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([pdf, 'Failed', 'NA', 'NA' f'Unexpected error: {str(e)}'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
